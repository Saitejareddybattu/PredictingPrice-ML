{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.035384,
     "end_time": "2021-05-22T15:48:26.615695",
     "exception": false,
     "start_time": "2021-05-22T15:48:26.580311",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Abstract\n",
    " \n",
    "\n",
    "Approximately 40 million used vehicles are sold each year. Effective pricing strategies can help any company to efficiently sell its products in a competitive market and making profit. In the automotive sector, pricing analytics play an essential role for both companies and individuals to assess the market price of a vehicle before putting it on sale or buying it. And, the rise of used cars sales is exponentially increasing. Car sellers sometimes take advantage of this scenario by listing unrealistic prices owing to the demand.\n",
    "\n",
    "Therefore, arises a need for a model that can assign a price for a vehicle by evaluating its features taking the prices of other cars into consideration. In this Notebook, we use supervised learning methods to predict the prices of used cars. The model has been chosen after careful exploratory data analysis to determine the impact of each feature on price. \n",
    "\n",
    "So, we propose a methodology using Machine Learning models to predict the prices of used cars given the features. The price is estimated based on the number of features as mentioned above.\n",
    "\n",
    "Notebook outline:\n",
    "\n",
    "+ Step 1, we collect the data about used cars, identify important features that reflect the price.\n",
    "+ Step 2, we preprocess and remove entries with NA values. Discard features that are not relevant for the prediction of the price.\n",
    "+ Step 3, we apply ML models on the preprocessed dataset with features as inputs and the price as output.\n",
    "\n",
    "By applying 9 models, the GradientBoostingRegressor gives very encouraging results with 99.1% on training set and 96.2% accuracy on prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.053583,
     "end_time": "2021-05-22T15:48:26.701630",
     "exception": false,
     "start_time": "2021-05-22T15:48:26.648047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032151,
     "end_time": "2021-05-22T15:48:26.768100",
     "exception": false,
     "start_time": "2021-05-22T15:48:26.735949",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# I. INTRODUCTION\n",
    "\n",
    "The prices of new cars in the industry is fixed by the manufacturer with some additional costs incurred by the Government in the form of taxes. So customers buying a new car can be assured of the money they invest to be worthy. But due to the increased price of new cars and the incapability of customers to buy new cars due to the lack of funds, used cars sales are on a global increase. Predicting the prices of used cars is an interesting and much-needed problem to be addressed. Customers can be widely exploited by fixing unrealistic prices for the used cars and many falls into this trap. Therefore, rises an absolute necessity of a used car price prediction system to effectively determine the worthiness of the car using a variety of features. Due to the adverse pricing of cars and the nomadic nature of people in developed countries, the cars are mostly bought on a lease basis, where there is an agreement between the buyer and seller. These cars upon completion of the agreement are resold. So reselling has become an essential part of today’s world. \n",
    "\n",
    "Given the description of used cars, the prediction of used cars is not an easy task. There are a variety of features of a car like the age of the car, its make, the origin of the car (the original country of the manufacturer), its mileage (the number of mildes it has run) and its horsepower. Due to rising fuel prices, fuel economy is also of prime importance. Other factors such as the type of fuel it uses, style, braking system, the volume of its cylinders (measured in cc), acceleration, the number of doors, safety index, size, weight, height, paint color, consumer reviews, prestigious awards won by the car manufacturer.\n",
    "\n",
    "Other options such as sound system, air conditioner, power steering, cosmic wheels, GPS navigator all may influence the\n",
    "price as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.0326,
     "end_time": "2021-05-22T15:48:26.833691",
     "exception": false,
     "start_time": "2021-05-22T15:48:26.801091",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# II. DATA SET AND PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033333,
     "end_time": "2021-05-22T15:48:26.899258",
     "exception": false,
     "start_time": "2021-05-22T15:48:26.865925",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We use dataset from Kaggle for used car price prediction. The dataset contains various features that are required to predict and classify the range of prices of used cars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "papermill": {
     "duration": 0.087712,
     "end_time": "2021-05-22T15:48:27.021389",
     "exception": false,
     "start_time": "2021-05-22T15:48:26.933677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('E:/2021 projects/truevolts/car reselling/train-data.csv')\n",
    "test = pd.read_csv('E:/2021 projects/truevolts/car reselling/test-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032842,
     "end_time": "2021-05-22T15:48:27.087029",
     "exception": false,
     "start_time": "2021-05-22T15:48:27.054187",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Firstly, we imported some basic Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "papermill": {
     "duration": 2.022697,
     "end_time": "2021-05-22T15:48:29.143318",
     "exception": false,
     "start_time": "2021-05-22T15:48:27.120621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032006,
     "end_time": "2021-05-22T15:48:29.211516",
     "exception": false,
     "start_time": "2021-05-22T15:48:29.179510",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "And Libraries for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "papermill": {
     "duration": 1.062319,
     "end_time": "2021-05-22T15:48:30.307168",
     "exception": false,
     "start_time": "2021-05-22T15:48:29.244849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 126] The specified module could not be found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-0e54a373c0e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLGBMClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_classification\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\lightgbm\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBooster\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregister_logger\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_evaluation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecord_evaluation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset_parameter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCVBooster\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m \u001b[0m_LIB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m_load_lib\u001b[1;34m()\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[0mlib\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcdll\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLoadLibrary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m     \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0mcallback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCFUNCTYPE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\ctypes\\__init__.py\u001b[0m in \u001b[0;36mLoadLibrary\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mLoadLibrary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dlltype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[0mcdll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLibraryLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\ctypes\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 126] The specified module could not be found"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor,AdaBoostRegressor,BaggingRegressor, RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.055341,
     "end_time": "2021-05-22T15:48:30.395976",
     "exception": false,
     "start_time": "2021-05-22T15:48:30.340635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.044292,
     "end_time": "2021-05-22T15:48:30.474140",
     "exception": false,
     "start_time": "2021-05-22T15:48:30.429848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032998,
     "end_time": "2021-05-22T15:48:30.541240",
     "exception": false,
     "start_time": "2021-05-22T15:48:30.508242",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's drop the 'New_Price' and 'Unnamed:0' columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.053687,
     "end_time": "2021-05-22T15:48:30.632262",
     "exception": false,
     "start_time": "2021-05-22T15:48:30.578575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data.drop('New_Price', axis=1)\n",
    "data = data.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "test = test.drop('New_Price', axis=1)\n",
    "test = test.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03448,
     "end_time": "2021-05-22T15:48:30.702441",
     "exception": false,
     "start_time": "2021-05-22T15:48:30.667961",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "And, drop all NaN data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.050956,
     "end_time": "2021-05-22T15:48:30.787525",
     "exception": false,
     "start_time": "2021-05-22T15:48:30.736569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data.dropna(how='any')\n",
    "test = test.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.040963,
     "end_time": "2021-05-22T15:48:30.862424",
     "exception": false,
     "start_time": "2021-05-22T15:48:30.821461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.042232,
     "end_time": "2021-05-22T15:48:30.939702",
     "exception": false,
     "start_time": "2021-05-22T15:48:30.897470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.035913,
     "end_time": "2021-05-22T15:48:31.010350",
     "exception": false,
     "start_time": "2021-05-22T15:48:30.974437",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "For this dataset ưe found one point very interesting for the Name of the vehicle. We noticed that there weren't any rules for vehicle naming, and duting the prediction step, we reconigned that the names of the vehicles in train_data and test_data are very different and not predictable. We check the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.044383,
     "end_time": "2021-05-22T15:48:31.089591",
     "exception": false,
     "start_time": "2021-05-22T15:48:31.045208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "listtrain = data['Name']\n",
    "listtest = test['Name']\n",
    "  \n",
    "# prints the missing in listrain \n",
    "print(\"Missing values in first list:\", (set(listtest).difference(listtrain))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.034966,
     "end_time": "2021-05-22T15:48:31.161299",
     "exception": false,
     "start_time": "2021-05-22T15:48:31.126333",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Therefore, we decided to create a new column under the name \"Cars\" to distinguish the car make & model. We have noticed that some authors have used the coding of vehicle names by specifying each vehicle as a separate code and conducting train and prediction, which is probably not LOGICAL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.076215,
     "end_time": "2021-05-22T15:48:31.274353",
     "exception": false,
     "start_time": "2021-05-22T15:48:31.198138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['Cars'] = data['Name'].str.split(\" \").str[0] + ' ' +data['Name'].str.split(\" \").str[1]\n",
    "test['Cars'] = test['Name'].str.split(\" \").str[0] + ' ' +test['Name'].str.split(\" \").str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.045499,
     "end_time": "2021-05-22T15:48:31.356463",
     "exception": false,
     "start_time": "2021-05-22T15:48:31.310964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "set(test['Cars']).issubset(set(data['Cars']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.036994,
     "end_time": "2021-05-22T15:48:31.430356",
     "exception": false,
     "start_time": "2021-05-22T15:48:31.393362",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, check again, and efectively, there are only 7 cars in the test data set are missing from the train data set. Fine, we drop these items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.046891,
     "end_time": "2021-05-22T15:48:31.515022",
     "exception": false,
     "start_time": "2021-05-22T15:48:31.468131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "listtrain = data['Cars']\n",
    "listtest = test['Cars']\n",
    "  \n",
    "# prints the missing and additional elements in list1 \n",
    "print(\"Missing values in first list:\", (set(listtest).difference(listtrain))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.049176,
     "end_time": "2021-05-22T15:48:31.600428",
     "exception": false,
     "start_time": "2021-05-22T15:48:31.551252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test.drop(test[test['Cars'].isin(['Toyota Land', 'Hindustan Motors', 'Fiat Abarth', 'Nissan 370Z', \n",
    "                                  'Isuzu MU', 'Bentley Flying', 'OpelCorsa 1.4Gsi'])].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.044118,
     "end_time": "2021-05-22T15:48:31.680233",
     "exception": false,
     "start_time": "2021-05-22T15:48:31.636115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.04624,
     "end_time": "2021-05-22T15:48:31.762285",
     "exception": false,
     "start_time": "2021-05-22T15:48:31.716045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "listtrain = data['Cars']\n",
    "listtest = test['Cars']\n",
    "  \n",
    "# prints the missing and additional elements in list1 \n",
    "print(\"Missing values in first list:\", (set(listtest).difference(listtrain))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.059004,
     "end_time": "2021-05-22T15:48:31.858572",
     "exception": false,
     "start_time": "2021-05-22T15:48:31.799568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.038359,
     "end_time": "2021-05-22T15:48:31.936504",
     "exception": false,
     "start_time": "2021-05-22T15:48:31.898145",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, we will convert all data of columns \"Mileage\", \"Engine\", \"Power\", \"Seats\" into float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.083726,
     "end_time": "2021-05-22T15:48:32.057134",
     "exception": false,
     "start_time": "2021-05-22T15:48:31.973408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['Mileage'] = data['Mileage'].str.replace(' kmpl','')\n",
    "data['Mileage'] = data['Mileage'].str.replace(' km/kg','')\n",
    "data['Engine'] = data['Engine'].str.replace(' CC','')\n",
    "data['Power'] = data['Power'].str.replace('null bhp','112')\n",
    "data['Power'] = data['Power'].str.replace(' bhp','')\n",
    "\n",
    "test['Mileage'] = test['Mileage'].str.replace(' kmpl','')\n",
    "test['Mileage'] = test['Mileage'].str.replace(' km/kg','')\n",
    "test['Engine'] = test['Engine'].str.replace(' CC','')\n",
    "test['Power'] = test['Power'].str.replace('null bhp','112')\n",
    "test['Power'] = test['Power'].str.replace(' bhp','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.052279,
     "end_time": "2021-05-22T15:48:32.147370",
     "exception": false,
     "start_time": "2021-05-22T15:48:32.095091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.048922,
     "end_time": "2021-05-22T15:48:32.239144",
     "exception": false,
     "start_time": "2021-05-22T15:48:32.190222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.046939,
     "end_time": "2021-05-22T15:48:32.323605",
     "exception": false,
     "start_time": "2021-05-22T15:48:32.276666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.056579,
     "end_time": "2021-05-22T15:48:32.420168",
     "exception": false,
     "start_time": "2021-05-22T15:48:32.363589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['Mileage'] = data['Mileage'].astype(float)\n",
    "data['Mileage'] = data['Mileage'].astype(float)\n",
    "data['Engine'] = data['Engine'].astype(float)\n",
    "data['Power'] = data['Power'].astype(float)\n",
    "\n",
    "test['Mileage'] = test['Mileage'].astype(float)\n",
    "test['Mileage'] = test['Mileage'].astype(float)\n",
    "test['Engine'] = test['Engine'].astype(float)\n",
    "test['Power'] = test['Power'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.076267,
     "end_time": "2021-05-22T15:48:32.535773",
     "exception": false,
     "start_time": "2021-05-22T15:48:32.459506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.048831,
     "end_time": "2021-05-22T15:48:32.623961",
     "exception": false,
     "start_time": "2021-05-22T15:48:32.575130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature = ['Cars', 'Location', 'Year', 'Kilometers_Driven', 'Fuel_Type', 'Transmission', \n",
    "           'Owner_Type', 'Mileage', 'Engine', 'Power', 'Seats','Price']\n",
    "data = pd.DataFrame(data, columns=feature)\n",
    "\n",
    "feature1 = ['Cars', 'Location', 'Year', 'Kilometers_Driven', 'Fuel_Type', 'Transmission', \n",
    "            'Owner_Type', 'Mileage', 'Engine', 'Power', 'Seats']\n",
    "test = pd.DataFrame(test, columns=feature1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.037915,
     "end_time": "2021-05-22T15:48:32.700664",
     "exception": false,
     "start_time": "2021-05-22T15:48:32.662749",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# III. EXPLORATORY DATA ANALYSIS\n",
    "\n",
    "After preprocessing the data, it is analyzed through visual exploration to gather insights about the model that\n",
    "can be applied to the data, understand the diversity in the data and the range of every field. We use a bar chart, box\n",
    "plot, distribution graph, etc. to explore each feature varies and its relation with other features including the target\n",
    "feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.056502,
     "end_time": "2021-05-22T15:48:32.796989",
     "exception": false,
     "start_time": "2021-05-22T15:48:32.740487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.039216,
     "end_time": "2021-05-22T15:48:32.876824",
     "exception": false,
     "start_time": "2021-05-22T15:48:32.837608",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, let's check the Price first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.298518,
     "end_time": "2021-05-22T15:48:33.214426",
     "exception": false,
     "start_time": "2021-05-22T15:48:32.915908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.distplot(data['Price'])\n",
    "\n",
    "print(\"Skewness: %f\" % data['Price'].skew())\n",
    "print(\"Kurtosis: %f\" % data['Price'].kurt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.040514,
     "end_time": "2021-05-22T15:48:33.296436",
     "exception": false,
     "start_time": "2021-05-22T15:48:33.255922",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can observe that the distribution of prices shows a high positive skewness to the left (skew > 1). A kurtosis value of 17 is very high, meaning that there is a profusion of outliers in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.494416,
     "end_time": "2021-05-22T15:48:33.831954",
     "exception": false,
     "start_time": "2021-05-22T15:48:33.337538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#applying log transformation\n",
    "data['Price'] = np.log(data['Price'])\n",
    "#transformed histogram and normal probability plot\n",
    "#sns.distplot(data['Price']);\n",
    "sns.distplot(data['Price'], fit=None);\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(data['Price'], plot=plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.043255,
     "end_time": "2021-05-22T15:48:33.917263",
     "exception": false,
     "start_time": "2021-05-22T15:48:33.874008",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We found that converting the value of Price to Log(Price) might be a good solution to have a more normal visualization of the distribution of the Price, however, this alternative has no major or decisive effect on the results of the train and/ or predict procedure in the next section. Therefore, in order not to complicate matters, we decided to keep the whole processed database up to this step to analyze the parameters' correlations and conduct the modeling in the following section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.042035,
     "end_time": "2021-05-22T15:48:34.000527",
     "exception": false,
     "start_time": "2021-05-22T15:48:33.958492",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# RELATIONSHIP OF PRICE WITH OTHER PARAMETER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.057979,
     "end_time": "2021-05-22T15:48:34.099901",
     "exception": false,
     "start_time": "2021-05-22T15:48:34.041922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find most important features relative to target Price\n",
    "print(\"Find most important features relative to Price-target\")\n",
    "corr = data.corr()\n",
    "corr.sort_values([\"Price\"], ascending = False, inplace = True)\n",
    "print(corr.Price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.334271,
     "end_time": "2021-05-22T15:48:35.478470",
     "exception": false,
     "start_time": "2021-05-22T15:48:34.144199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "px.treemap(data.groupby(by='Fuel_Type').sum().reset_index(), path=['Fuel_Type'], labels='Fuel_Type', \n",
    "           values='Price', title='Price vs Fuel_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.045759,
     "end_time": "2021-05-22T15:48:35.570213",
     "exception": false,
     "start_time": "2021-05-22T15:48:35.524454",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Wow, Diesel vehicles are the majority, NOT petrole cars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.245331,
     "end_time": "2021-05-22T15:48:36.860729",
     "exception": false,
     "start_time": "2021-05-22T15:48:35.615398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "yprop = 'Price'\n",
    "xprop = 'Power'\n",
    "h= 'Fuel_Type'\n",
    "px.scatter(data, x=xprop, y=yprop, color=h, marginal_y=\"violin\", marginal_x=\"box\", trendline=\"ols\", template=\"simple_white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.228331,
     "end_time": "2021-05-22T15:48:37.143970",
     "exception": false,
     "start_time": "2021-05-22T15:48:36.915639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "yprop = 'Price'\n",
    "xprop = 'Engine'\n",
    "h= 'Transmission'\n",
    "px.scatter(data, x=xprop, y=yprop, color=h, marginal_y=\"violin\", marginal_x=\"box\", trendline=\"ols\", template=\"simple_white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.886674,
     "end_time": "2021-05-22T15:48:38.099580",
     "exception": false,
     "start_time": "2021-05-22T15:48:37.212906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "xprop = 'Year'\n",
    "yprop = 'Price'\n",
    "sns.boxplot(data=data, x=xprop, y=yprop, hue='Transmission')\n",
    "plt.xlabel('{} range'.format(xprop), size=14)\n",
    "plt.ylabel('Number of {}'.format(yprop), size=14)\n",
    "plt.title('Boxplot of {}'.format(yprop), size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.067876,
     "end_time": "2021-05-22T15:48:38.233308",
     "exception": false,
     "start_time": "2021-05-22T15:48:38.165432",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Yeah ! \"New\" cars are more expensive than \"Old\" cars, and Automatic cars are more costly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.269826,
     "end_time": "2021-05-22T15:48:38.573167",
     "exception": false,
     "start_time": "2021-05-22T15:48:38.303341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "yprop = 'Price'\n",
    "xprop = 'Year'\n",
    "h= 'Owner_Type'\n",
    "px.scatter(data, x=xprop, y=yprop, color=h, marginal_y=\"violin\", marginal_x=\"box\", trendline=\"ols\", template=\"simple_white\")\n",
    "#fig.update_layout(xaxis_range=[0,5e5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.082467,
     "end_time": "2021-05-22T15:48:38.739623",
     "exception": false,
     "start_time": "2021-05-22T15:48:38.657156",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It's quite BIZZA that, the THIRD OWNER' CARS are sometime more expensive than the second-hand :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.139877,
     "end_time": "2021-05-22T15:48:39.965799",
     "exception": false,
     "start_time": "2021-05-22T15:48:38.825922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "xprop = 'Year'\n",
    "yprop = 'Price'\n",
    "sns.boxplot(data=data, x=xprop, y=yprop, hue='Fuel_Type')\n",
    "plt.xlabel('{} range'.format(xprop), size=14)\n",
    "plt.ylabel('Number of {}'.format(yprop), size=14)\n",
    "plt.title('Boxplot of {}'.format(yprop), size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.220173,
     "end_time": "2021-05-22T15:48:40.298451",
     "exception": false,
     "start_time": "2021-05-22T15:48:40.078278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = px.box(data, x='Fuel_Type',y='Price', color='Transmission', notched=True)\n",
    "fig.update_layout(legend=dict(orientation=\"h\",yanchor=\"bottom\",y=1.02,xanchor=\"right\",x=1))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.084571,
     "end_time": "2021-05-22T15:48:40.474995",
     "exception": false,
     "start_time": "2021-05-22T15:48:40.390424",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Again, this confirmed that the Petrol vehicle is cheaper than the Diesel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.653242,
     "end_time": "2021-05-22T15:48:41.215446",
     "exception": false,
     "start_time": "2021-05-22T15:48:40.562204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "px.violin(data, y='Price', x='Seats', color=None, box=True, points=\"all\", hover_data=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.176921,
     "end_time": "2021-05-22T15:48:41.510589",
     "exception": false,
     "start_time": "2021-05-22T15:48:41.333668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "fig = go.Figure(data=[go.Pie(labels=data['Fuel_Type'], values=data['Price'], hole=.3)])\n",
    "fig.update_layout(legend=dict(orientation=\"h\", yanchor=\"bottom\",y=1.02,xanchor=\"right\",x=1))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.117489,
     "end_time": "2021-05-22T15:48:41.747047",
     "exception": false,
     "start_time": "2021-05-22T15:48:41.629558",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IV. MODEL DESCRIPTION\n",
    "\n",
    "To compute the price for vehicles, this platform may compute linear regression model that defines a set of input variables. However, it does not give details as what features can be used for specific type of vehicles for such prediction. We have taken important features for predicting the price of used cars using random forest models.\n",
    "\n",
    "Zhang et al. [2] use Kaggle data-set to perform price prediction of a used car. The author evaluates the performance\n",
    "of several classification methods (logistic regression, SVM, decision tree, Extra Trees, AdaBoost, random forest) to assess\n",
    "the performance. Among all these models, random forest classifier proves to perform the best for their prediction task.\n",
    "\n",
    "This work uses eleven (11) features ('Cars', 'Location', 'Year', 'Kilometers_Driven', 'Fuel_Type', 'Transmission', 'Owner_Type', 'Mileage', 'Engine', 'Power', 'Seats') to perform the classification task after removal of irrelevant features from the dataset which gives an accuracy of 96.2% on the test data. We also use Kaggle data-set to perform prediction of used-car prices. \n",
    "\n",
    "Work by Durgesh et al. [4] gives a good introductory paper on Support Vector Machine. The authors assess the performance of several classification techniques (K-NN, RuleBased Classifiers, etc.) by performing the comparative assessment of SVM with others. This comparative study is done using several data-sets taken from the UCI Machine Learning Repository. This assessment yields that SVM gives much better classification accuracy in comparison to others.\n",
    "\n",
    "The Author of the paper [5] predicts the price of used cars in Mauritius by using four comparable machine learning algorithms - multiple linear regression, k-nearest neighbors, naive Bayes and decision trees algorithm. The author uses historical data collected from daily newspapers in Mauritius. The application of listed learning algorithms on this data provides comparable results with not-so-good prediction accuracy. The main difference, however, between classifying price range and spam mail, is that spam email classification task is a binary one, whereas our motive is mainly one-vs-therest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.123689,
     "end_time": "2021-05-22T15:48:41.987060",
     "exception": false,
     "start_time": "2021-05-22T15:48:41.863371",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**A. Data preparation & Model Parameters**\n",
    "\n",
    "In this Notebook, we do not discuss in deep about the Models' parameters, we just applied the standard or refer to previous recommendations. Let's copy the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.134893,
     "end_time": "2021-05-22T15:48:42.311077",
     "exception": false,
     "start_time": "2021-05-22T15:48:42.176184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "df_train=copy.deepcopy(data)\n",
    "df_test=copy.deepcopy(test)\n",
    "\n",
    "cols=np.array(data.columns[data.dtypes != object])\n",
    "for i in df_train.columns:\n",
    "    if i not in cols:\n",
    "        df_train[i]=df_train[i].map(str)\n",
    "        df_test[i]=df_test[i].map(str)\n",
    "df_train.drop(columns=cols,inplace=True)\n",
    "df_test.drop(columns=np.delete(cols,len(cols)-1),inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.109035,
     "end_time": "2021-05-22T15:48:42.532480",
     "exception": false,
     "start_time": "2021-05-22T15:48:42.423445",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "And then, coding the categorical parameters using LabelEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.144621,
     "end_time": "2021-05-22T15:48:42.790270",
     "exception": false,
     "start_time": "2021-05-22T15:48:42.645649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "\n",
    "# build dictionary function\n",
    "cols=np.array(data.columns[data.dtypes != object])\n",
    "d = defaultdict(LabelEncoder)\n",
    "\n",
    "# only for categorical columns apply dictionary by calling fit_transform \n",
    "df_train = df_train.apply(lambda x: d[x.name].fit_transform(x))\n",
    "df_test = df_test.apply(lambda x: d[x.name].transform(x))\n",
    "df_train[cols] = data[cols]\n",
    "df_test[np.delete(cols,len(cols)-1)]=test[np.delete(cols,len(cols)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.136011,
     "end_time": "2021-05-22T15:48:43.041830",
     "exception": false,
     "start_time": "2021-05-22T15:48:42.905819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.130402,
     "end_time": "2021-05-22T15:48:43.311758",
     "exception": false,
     "start_time": "2021-05-22T15:48:43.181356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.111053,
     "end_time": "2021-05-22T15:48:43.532126",
     "exception": false,
     "start_time": "2021-05-22T15:48:43.421073",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**B. Training and Testing**\n",
    "\n",
    "We split our dataset into training, testing data with a 70:30 split ratio. The splitting was done by picking at random which results in a balance between the training data and testing data amongst the whole dataset. This is done to avoid overfitting and enhance generalization. Finaly, we selected 11 characters in the dataset to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.119516,
     "end_time": "2021-05-22T15:48:43.763319",
     "exception": false,
     "start_time": "2021-05-22T15:48:43.643803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ftrain = ['Cars', 'Location', 'Year', 'Kilometers_Driven', 'Fuel_Type', 'Transmission', \n",
    "          'Owner_Type', 'Mileage', 'Engine', 'Power', 'Seats','Price']\n",
    "\n",
    "def Definedata():\n",
    "    # define dataset\n",
    "    data2 = df_train[ftrain]\n",
    "    X = data2.drop(columns=['Price']).values\n",
    "    y0 = data2['Price'].values\n",
    "    lab_enc = preprocessing.LabelEncoder()\n",
    "    y = lab_enc.fit_transform(y0)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.115265,
     "end_time": "2021-05-22T15:48:43.993182",
     "exception": false,
     "start_time": "2021-05-22T15:48:43.877917",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, we create different functions to calculate deviations, important features and graphical illustration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.128915,
     "end_time": "2021-05-22T15:48:44.242980",
     "exception": false,
     "start_time": "2021-05-22T15:48:44.114065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Models(models):\n",
    "    \n",
    "    model = models\n",
    "    X, y = Definedata()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 25)\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_total = model.predict(X)\n",
    "    \n",
    "    print(\"\\t\\tError Table\")\n",
    "    print('Mean Absolute Error      : ', metrics.mean_absolute_error(y_test, y_pred))\n",
    "    print('Mean Squared  Error      : ', metrics.mean_squared_error(y_test, y_pred))\n",
    "    print('Root Mean Squared  Error : ', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "    print('Accuracy on Traing set   : ', model.score(X_train,y_train))\n",
    "    print('Accuracy on Testing set  : ', model.score(X_test,y_test))\n",
    "    return y_total, y\n",
    "\n",
    "def Featureimportances(models):\n",
    "    model = models\n",
    "    model.fit(X_train,y_train)\n",
    "    importances = model.feature_importances_\n",
    "    features = df_test.columns[:9]\n",
    "    imp = pd.DataFrame({'Features': ftest, 'Importance': importances})\n",
    "    imp['Sum Importance'] = imp['Importance'].cumsum()\n",
    "    imp = imp.sort_values(by = 'Importance')\n",
    "    return imp\n",
    "\n",
    "def Graph_prediction(n, y_actual, y_predicted):\n",
    "    y = y_actual\n",
    "    y_total = y_predicted\n",
    "    number = n\n",
    "    aa=[x for x in range(number)]\n",
    "    plt.figure(figsize=(25,10)) \n",
    "    plt.plot(aa, y[:number], marker='.', label=\"actual\")\n",
    "    plt.plot(aa, y_total[:number], 'b', label=\"prediction\")\n",
    "    plt.xlabel('Price prediction of first {} used cars'.format(number), size=15)\n",
    "    plt.legend(fontsize=15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.111245,
     "end_time": "2021-05-22T15:48:44.462618",
     "exception": false,
     "start_time": "2021-05-22T15:48:44.351373",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Firstly, take a quick look at the correlation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.651458,
     "end_time": "2021-05-22T15:48:45.225552",
     "exception": false,
     "start_time": "2021-05-22T15:48:44.574094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "style.use('ggplot')\n",
    "sns.set_style('whitegrid')\n",
    "plt.subplots(figsize = (12,7))\n",
    "## Plotting heatmap. # Generate a mask for the upper triangle (taken from seaborn example gallery)\n",
    "mask = np.zeros_like(df_train.corr(), dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(df_train.corr(), cmap=sns.diverging_palette(20, 220, n=200), annot=True, mask=mask, center = 0, );\n",
    "plt.title(\"Heatmap of all the Features of Train data set\", fontsize = 25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.10935,
     "end_time": "2021-05-22T15:48:45.445101",
     "exception": false,
     "start_time": "2021-05-22T15:48:45.335751",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**C. Models comparison**\n",
    "\n",
    "The model score is the coefficient of determination R2 of the prediction. In total, we have examinated 9 models to train/predict the used cars price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.120309,
     "end_time": "2021-05-22T15:48:45.674629",
     "exception": false,
     "start_time": "2021-05-22T15:48:45.554320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Acc = pd.DataFrame(index=None, columns=['model','Root Mean Squared  Error','Accuracy on Traing set','Accuracy on Testing set'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 4.827902,
     "end_time": "2021-05-22T15:48:50.614055",
     "exception": false,
     "start_time": "2021-05-22T15:48:45.786153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X, y = Definedata()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 25)\n",
    "    \n",
    "regressors = [['DecisionTreeRegressor',DecisionTreeRegressor()],\n",
    "              ['XGBRegressor', XGBRegressor()],\n",
    "              ['RandomForestRegressor', RandomForestRegressor()],\n",
    "              ['MLPRegressor',MLPRegressor()],\n",
    "              ['AdaBoostRegressor',AdaBoostRegressor()],\n",
    "              ['ExtraTreesRegressor',ExtraTreesRegressor()]]\n",
    "\n",
    "for mod in regressors:\n",
    "    name = mod[0]\n",
    "    model = mod[1]\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "    ATrS =  model.score(X_train,y_train)\n",
    "    ATeS = model.score(X_test,y_test)\n",
    "    \n",
    "    Acc = Acc.append(pd.Series({'model':name, 'Root Mean Squared  Error': RMSE,'Accuracy on Traing set':ATrS,'Accuracy on Testing set':ATeS}),ignore_index=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.12227,
     "end_time": "2021-05-22T15:48:50.846044",
     "exception": false,
     "start_time": "2021-05-22T15:48:50.723774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Acc.sort_values(by='Accuracy on Testing set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 101.641761,
     "end_time": "2021-05-22T15:50:32.600368",
     "exception": false,
     "start_time": "2021-05-22T15:48:50.958607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_predicted, y_actual = Models(RandomForestRegressor(n_estimators=10000,min_samples_split=2,min_samples_leaf=1,max_features='sqrt',max_depth=25))\n",
    "Graph_prediction(150, y_actual, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 16.202849,
     "end_time": "2021-05-22T15:50:48.935508",
     "exception": false,
     "start_time": "2021-05-22T15:50:32.732659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_predicted, y_actual = Models(GradientBoostingRegressor(random_state=21, n_estimators=3000))\n",
    "Graph_prediction(150, y_actual, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "papermill": {
     "duration": 30.626834,
     "end_time": "2021-05-22T15:51:19.691560",
     "exception": false,
     "start_time": "2021-05-22T15:50:49.064726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_predicted, y_actual = Models(CatBoostRegressor(iterations= 10000, learning_rate= 0.02, random_state= 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.530502,
     "end_time": "2021-05-22T15:51:20.403651",
     "exception": false,
     "start_time": "2021-05-22T15:51:19.873149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Graph_prediction(150, y_actual, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.198137,
     "end_time": "2021-05-22T15:51:20.788155",
     "exception": false,
     "start_time": "2021-05-22T15:51:20.590018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "compare = pd.DataFrame({'Prediction': y_predicted, 'Test Data' : y_actual, 'Abs error': abs(y_actual - y_predicted), 'AAD%': abs(y_actual - y_predicted)/y_actual*100})\n",
    "compare.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 28.722512,
     "end_time": "2021-05-22T15:51:49.691031",
     "exception": false,
     "start_time": "2021-05-22T15:51:20.968519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor(random_state=21, n_estimators=5000)\n",
    "feature1 = ['Cars', 'Location', 'Year', 'Kilometers_Driven', 'Fuel_Type', 'Transmission', \n",
    "            'Owner_Type', 'Mileage', 'Engine', 'Power', 'Seats']\n",
    "\n",
    "X0 = df_test[feature1]\n",
    "X, y = Definedata()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 25)\n",
    "model.fit(X_train,y_train)\n",
    "y_predicted = model.predict(X0)\n",
    "\n",
    "submission = pd.DataFrame({'Car_id':test.index,'Price':y_predicted}) \n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.440198,
     "end_time": "2021-05-22T15:51:50.315601",
     "exception": false,
     "start_time": "2021-05-22T15:51:49.875403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Convert DataFrame to a csv file that can be uploaded\n",
    "#This is saved in the same directory as your notebook\n",
    "filename = 'submission.csv'\n",
    "\n",
    "submission.to_csv(filename,index=True)\n",
    "\n",
    "print('Saved file: ' + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.188034,
     "end_time": "2021-05-22T15:51:50.686222",
     "exception": false,
     "start_time": "2021-05-22T15:51:50.498188",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# V. CONCLUSION\n",
    "\n",
    "This Notebook evaluates used-car price prediction using Kaggle dataset which gives the best accuracy of 96.2% for test data and\n",
    "99.1% for train-data. Being a sophisticated model, GradientBoostingRegressor gives the BEST accuracy in comparison to all prior works using these datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.189722,
     "end_time": "2021-05-22T15:51:51.063618",
     "exception": false,
     "start_time": "2021-05-22T15:51:50.873896",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# VI. FUTURE WORKS\n",
    "\n",
    "Keeping the current model as a baseline, we intend to use some advanced techniques algorithms to predict car prices as our future work. We intend to develop a fully automatic, interactive system that contains a repository of used-cars with their prices. This enables a user to know the price of a similar car using a recommendation engine, which we would work in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.196253,
     "end_time": "2021-05-22T15:51:51.453855",
     "exception": false,
     "start_time": "2021-05-22T15:51:51.257602",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# VII. REFERENCES\n",
    "\n",
    "[1] Strauss, Oliver Thomas, and Morgan Scott Hansen. \"Advanced data science systems and methods useful for auction pricing optimization over network.\" U.S. Patent Application No. 15/213,941.\n",
    "\n",
    "[2] Xinyuan Zhang , Zhiye Zhang and Changtong Qiu, “Model of Predicting the Price Range of Used Car”, 2017\n",
    "\n",
    "[3] W.A. Awad and S.M. ELseuofi, “Machine Learning Method for SpamEmail Classification”, 2011\n",
    "\n",
    "[4] Durgesh K. Srivastava, Lekha Bhambhu, “Data Classification Method using Support Vector Machine”, 2009\n",
    "\n",
    "[5] Pudaruth, Sameerchand. \"Predicting the price of used cars using machine learning techniques.\" Int. J. Inf. Comput. Technol 4.7 (2014): 753-764.\n",
    "\n",
    "[6] Noor, Kanwal, and Sadaqat Jan. \"Vehicle Price Prediction System using Machine Learning Techniques.\" International Journal of Computer Applications 167.9 (2017).\n",
    "\n",
    "[7] Kuiper, Shonda. \"Introduction to Multiple Regression: How Much Is Your Car Worth?.\" Journal of Statistics Education 16.3 (2008)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "papermill": {
   "duration": 210.102363,
   "end_time": "2021-05-22T15:51:51.856421",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-22T15:48:21.754058",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
